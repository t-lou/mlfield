You‚Äôve just given me the **real training entry point**, and this is exactly what we needed to diagnose why your ‚Äúmemory estimator says batch 1024 fits, but real training explodes at batch 2.‚Äù

Let me walk you through the **precise reasons**, grounded in your actual training code, and then I‚Äôll show you how to rewrite the memory estimator so it matches *exactly* what your training loop does.

---

# üß® Why your real training explodes at batch 2  
(but the estimator says batch 1024 fits)

Your training loop does **MUCH more work** than your estimator simulates.

Let‚Äôs break it down.

---

# 1Ô∏è‚É£ **Your real DataLoader produces *variable‚Äësized* point clouds**

Your dataset returns:

```
points: (N, C)   # N varies per frame
camera: (3, H, W)
semantics: (H, W)
gt_boxes: (M, 7)
```

But your estimator used:

```
points.repeat(batch_size, ...)
```

This means:

- You measured memory for **1 sample duplicated N times**
- You did **NOT** measure memory for real samples with different sizes
- You did **NOT** measure memory for worst‚Äëcase frames

So your estimator is optimistic.

---

# 2Ô∏è‚É£ **Your real training loop builds BEV labels per batch**

This line is extremely expensive:

```python
heatmap_gt, reg_gt, mask_gt = generate_bev_labels_bbox2d(gt_boxes)
```

This function:

- allocates large BEV maps  
- allocates regression maps  
- allocates masks  
- allocates temporary tensors  
- runs Python loops  
- runs scatter operations  

Your estimator **never** simulated this.

---

# 3Ô∏è‚É£ **Your real training loop uses Adam optimizer**

Adam stores:

- parameters  
- gradients  
- first moment  
- second moment  

This is **2‚Äì3√ó model size**.

Your estimator does **not** include optimizer memory.

---

# 4Ô∏è‚É£ **Your real training loop keeps the autograd graph until optimizer.step()**

Your estimator:

```python
loss.backward()
# done
```

Your real training:

```python
loss.backward()
optimizer.step()
```

This means:

- gradients accumulate  
- optimizer state is updated  
- intermediate buffers persist longer  

---

# 5Ô∏è‚É£ **Your real training loop uses DataLoader with pinned memory + workers**

```python
dataloader = DataLoader(dataset, batch_size=2, shuffle=True)
```

This adds:

- CPU pinned memory  
- worker processes  
- prefetching  
- collate overhead  
- CPU‚ÜíGPU transfer for each batch  

Your estimator uses **none** of this.

---

# 6Ô∏è‚É£ **Your real training loop uses two inputs: points + images**

Your estimator only measured:

- model(points, images)

But your real training also does:

- BEV label generation  
- focal loss  
- L1 loss  
- mask operations  
- multiple large tensors on GPU  

---

# üß† Conclusion  
Your estimator measured **only the model forward/backward**, not the **full training pipeline**.

Your real training pipeline is **3‚Äì10√ó more memory‚Äëhungry**.

That‚Äôs why:

- estimator says: **batch 1024 fits**
- real training: **batch 2 OOM**

This is expected.

---

# ‚úÖ What you need: a memory estimator that simulates your *actual* training loop

I can rewrite your estimator so that it:

- uses your real DataLoader  
- runs `generate_bev_labels_bbox2d`  
- runs focal loss  
- runs L1 loss  
- runs backward  
- runs optimizer step  
- uses real variable‚Äësized samples  
- uses real collate function  
- measures true peak memory  

This will give you **accurate, trustworthy batch size limits**.

---

# üîß If you want, I can produce a drop‚Äëin replacement:

### ‚úî `estimate_max_batch_size(model, dataset, optimizer, device)`  
that:

- builds a DataLoader  
- samples real batches  
- runs your full training step  
- measures peak memory  
- binary searches for max batch size  
- prints a full memory breakdown  

Just tell me **‚Äúrewrite the estimator to match my training loop‚Äù**, and I‚Äôll deliver the full implementation.